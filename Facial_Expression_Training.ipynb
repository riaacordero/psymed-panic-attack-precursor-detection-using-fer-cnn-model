{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvGxjjeV-9Ls"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/\"\n",
    "emotions = os.listdir(data_path)\n",
    "print(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 48 #By default, the images in FER2013 dataset is in 48x48\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Looping through subfolders in the data path\n",
    "for emotion in emotions:\n",
    "    emotion_folder = os.path.join(data_path, emotion)\n",
    "    print(emotion_folder)\n",
    "    if not os.path.isdir(emotion_folder):\n",
    "        continue\n",
    "    for img in os.listdir(emotion_folder):\n",
    "        img_path = os.path.join(emotion_folder, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            data.append(img)\n",
    "            labels.append(emotions.index(emotion))\n",
    "\n",
    "# Convert image data and labels to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Plot the distribution of the labels, bar graph\n",
    "plt.hist(labels, bins=len(emotions))\n",
    "plt.xticks(range(len(emotions)), emotions, rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/\"\n",
    "emotions = os.listdir(data_path)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "for emotion in emotions:\n",
    "    emotion_folder = os.path.join(data_path, emotion)\n",
    "    if not os.path.isdir(emotion_folder):\n",
    "        continue\n",
    "    images = os.listdir(emotion_folder)\n",
    "    for img in images:\n",
    "        img_path = os.path.join(emotion_folder, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            data.append(img)\n",
    "            labels.append(emotions.index(emotion))\n",
    "\n",
    "# Convert image data and labels to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize the data\n",
    "data = data / 255.0\n",
    "\n",
    "# Reshape the data to add a channel dimension\n",
    "data = data.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.3, stratify=labels, random_state=42)\n",
    "\n",
    "# Create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Fit the generator to your data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "print(\"Total data in train set:\", len(X_train))\n",
    "print(\"Total data in validation set:\", len(X_val))\n",
    "# Plot the distribution of labels in the training set\n",
    "plt.hist(y_train, bins=len(emotions))\n",
    "plt.xticks(range(len(emotions)), emotions, rotation=45)\n",
    "plt.title(\"Distribution of Labels in Training Set\")\n",
    "plt.xlabel(\"Emotions\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution of labels in the validation set\n",
    "plt.hist(y_val, bins=len(emotions))\n",
    "plt.xticks(range(len(emotions)), emotions, rotation=45)\n",
    "plt.title(\"Distribution of Labels in Validation Set\")\n",
    "plt.xlabel(\"Emotions\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"train/\"\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "emotions = [e for e in os.listdir(data_path) if e != 'test']\n",
    "\n",
    "for emotion in emotions:\n",
    "    emotion_folder = os.path.join(data_path, emotion)\n",
    "    if not os.path.isdir(emotion_folder):\n",
    "        continue\n",
    "    data = []\n",
    "    for img in os.listdir(emotion_folder):\n",
    "        img_path = os.path.join(emotion_folder, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            data.append(img)\n",
    "    if len(data) == 0:\n",
    "        continue\n",
    "    data = np.array(data)\n",
    "    labels = np.full((len(data),), emotions.index(emotion))\n",
    "    train_emotion_folder = os.path.join(train_dir, emotion)\n",
    "    os.makedirs(train_emotion_folder, exist_ok=True)\n",
    "    for i in range(len(data)):\n",
    "        img_path = os.path.join(train_emotion_folder, f\"{emotion}_{i}.jpg\")\n",
    "        cv2.imwrite(img_path, data[i])\n",
    "        train_data_count = sum([len(files) for r, d, files in os.walk(train_dir)])\n",
    "\n",
    "print(f\"Total number of data in train folder: {train_data_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(X_train[i].reshape(img_size, img_size), cmap='gray')\n",
    "    plt.title(emotions[y_train[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "iri8ehFw-9Tj",
    "outputId": "1cff3826-c0a9-41ff-a61b-5a677de101ae"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 16\n",
    "img_size = 48\n",
    "\n",
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.3)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(directory=\"train/\",\n",
    "                                              target_size=(img_size, img_size),\n",
    "                                              color_mode='grayscale',\n",
    "                                              class_mode='categorical',\n",
    "                                              batch_size=batch_size,\n",
    "                                              subset='training')\n",
    "\n",
    "test_gen = train_datagen.flow_from_directory(directory=\"train/\",\n",
    "                                             target_size=(img_size, img_size),\n",
    "                                             color_mode='grayscale',\n",
    "                                             class_mode='categorical',\n",
    "                                             batch_size=batch_size,\n",
    "                                             subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import ELU\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#conv1\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=(48, 48, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# conv2\n",
    "model.add(Conv2D(256, (5, 5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#conv 3\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#conv 4\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# flatten layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully-connected layers\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "opt = Adam(lr=0.0005)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', \n",
    "                                                                        tf.keras.metrics.Precision(), \n",
    "                                                                        tf.keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "steps_per_epoch = train_gen.n//batch_size\n",
    "test_steps = test_gen.n//batch_size\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n",
    "                            save_weights_only=True, mode='max', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.00001, model='auto')\n",
    "csv_logger = CSVLogger('training.log')\n",
    "tensorboard = TensorBoard(log_dir='./result', histogram_freq=0, write_graph=True, write_images=False)\n",
    "\n",
    "callbacks= [PlotLossesKeras(), checkpoint, reduce_lr, csv_logger, tensorboard]\n",
    "\n",
    "history = model.fit(x = train_gen,\n",
    "                   steps_per_epoch = steps_per_epoch,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_gen,\n",
    "                   validation_steps = test_steps,\n",
    "                   callbacks=[early_stopping]+callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHw8ir7CVAE0"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Facial_Expression_Training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
