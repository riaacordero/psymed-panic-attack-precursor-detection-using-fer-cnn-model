{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvGxjjeV-9Ls"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
    "from keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "from livelossplot import PlotLossesKeras\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"train/\"\n",
    "emotions = [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\n",
    "\n",
    "img_size = 48 #By default, the images in FER2013 dataset is in 48x48\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Looping through subfolders in the data path\n",
    "for emotion in emotions:\n",
    "    emotion_folder = os.path.join(data_path, emotion)\n",
    "    for img in os.listdir(emotion_folder):\n",
    "        img_path = os.path.join(emotion_folder, img)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        data.append(img)\n",
    "        labels.append(emotions.index(emotion))\n",
    "\n",
    "# Convert image data and labels to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Plot the distribution of the labels, bar graph\n",
    "plt.hist(labels, bins=len(emotions))\n",
    "plt.xticks(range(len(emotions)), emotions, rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "# Reshape the data to add a channel dimension\n",
    "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
    "X_val = X_val.reshape(-1, img_size, img_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(X_train[i].reshape(img_size, img_size), cmap='gray')\n",
    "    plt.title(emotions[y_train[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "iri8ehFw-9Tj",
    "outputId": "1cff3826-c0a9-41ff-a61b-5a677de101ae"
   },
   "outputs": [],
   "source": [
    "def train_data_generator(img_size, batch_size):\n",
    "    datagen_tr = ImageDataGenerator(horizontal_flip= True) #Randomly flips images along the horizontal axis\n",
    "    train_gen = datagen_tr.flow_from_directory(\"train/\",\n",
    "                                              target_size=(img_size, img_size),\n",
    "                                              color_mode='grayscale',\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "    return train_gen\n",
    "\n",
    "def test_data_generator(img_size, batch_size):\n",
    "    datagen_ts = ImageDataGenerator(horizontal_flip= True) #Randomly flips images along the horizontal axis\n",
    "    test_gen = datagen_ts.flow_from_directory(\"test/\",\n",
    "                                              target_size=(img_size, img_size),\n",
    "                                              color_mode='grayscale',\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=False)\n",
    "    return test_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#conv1\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(48, 48, 1))) # 48 = size, 1=grayscale (3 if rgb)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # shrinks size to 2\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# conv2\n",
    "\n",
    "model.add(Conv2D(128, (5, 5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # shrinks size to 2\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#conv 3\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # shrinks size to 2\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#conv 4\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) # shrinks size to 2\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# fully-connected layers\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "opt = Adam(lr=0.0005) #learning rate since it speeds up training, you can reduce to yor liking\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = train_data_generator(img_size, batch_size)\n",
    "test_gen = test_data_generator(img_size, batch_size)\n",
    "\n",
    "epochs = 25\n",
    "steps_per_epoch = train_gen.n//train_gen.batch_size\n",
    "test_steps = test_gen.n//test_gen.batch_size\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n",
    "                            save_weights_only=True, mode='max', verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.00001, model='auto')\n",
    "\n",
    "callbacks= [PlotLossesKeras(), checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit(x = train_gen,\n",
    "                   steps_per_epoch = steps_per_epoch,\n",
    "                   epochs=epochs,\n",
    "                   validation_data=test_gen,\n",
    "                   validation_steps = test_steps,\n",
    "                   callbacks=callbacks\n",
    "                   )\n",
    "\n",
    "# ACCURACY can be improved with longer training and epoch steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHw8ir7CVAE0"
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Facial_Expression_Training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
